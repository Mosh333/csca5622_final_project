{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc681e3-9691-4b83-950c-d2a93e53ead3",
   "metadata": {},
   "source": [
    "# CSCA 5622 Final Project - Consumer PC Hardware Trends and Predictions\n",
    "### By Moshiur Howlader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07e5d28-adc1-419a-8839-c35fb56b6529",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the digital age, computer hardware is ubiquitous, and its performance continues to improve year by year. Intel's co-founder provided valuable insight into how computers would evolve, known as **Moore's Law** ([see Wikipedia](https://en.wikipedia.org/wiki/Moore%27s_law)). This observation states that the number of transistors in an integrated circuit (IC) doubles approximately every two years. The chart below illustrates the trend from 1970 to 2020:\n",
    "\n",
    "<br><br>\n",
    "<img src=\"../images/moores_law_transistor_count_1970_2020.png\" alt=\"Transistor count over time\" width=\"1200\" height=\"800\">\n",
    "\n",
    "Based on Moore's Law, consumers might expect to get computer hardware with double the transistors every two years—leading to predictable and consistent increases in computing power. However, the reality is far more complex. As the number of transistors crammed into a fixed area increases, **quantum physics** begins to interfere, imposing physical limitations. These constraints prevent engineers from continuing to follow Moore's Law indefinitely. According to [nano.gov](https://www.nano.gov/nanotech-101/what/nano-size), the average size of a gold atom is 1/3 nm! Clearly, there is a limit to how many transistors can be packed into computer parts. Below are the trends in chip lithography size according to Wikipedia:\n",
    "\n",
    "| Feature Size | Year |\n",
    "|--------------|------|\n",
    "| 20 μm        | 1968 |\n",
    "| 10 μm        | 1971 |\n",
    "| 6 μm         | 1974 |\n",
    "| 3 μm         | 1977 |\n",
    "| 1.5 μm       | 1981 |\n",
    "| 1 μm         | 1984 |\n",
    "| 800 nm       | 1987 |\n",
    "| 600 nm       | 1990 |\n",
    "| 350 nm       | 1993 |\n",
    "| 250 nm       | 1996 |\n",
    "| 180 nm       | 1999 |\n",
    "| 130 nm       | 2001 |\n",
    "| 90 nm        | 2003 |\n",
    "| 65 nm        | 2005 |\n",
    "| 45 nm        | 2007 |\n",
    "| 32 nm        | 2009 |\n",
    "| 28 nm        | 2010 |\n",
    "| 22 nm        | 2012 |\n",
    "| 14 nm        | 2014 |\n",
    "| 10 nm        | 2016 |\n",
    "| 7 nm         | 2018 |\n",
    "| 5 nm         | 2020 |\n",
    "| 3 nm         | 2022 |\n",
    "| 2 nm         | ~2025 (Future) |\n",
    "\n",
    "According to Jensen Huang, the CEO of Nvidia, **Moore's Law is dead** ([TechSpot article](https://www.techspot.com/news/96094-nvidia-jensen-huang-once-again-claims-moore-law.html)). This statement seems reasonable given the physical limitations of current chip designs. As the rate of improvement in transistor count decreases year over year, will consumers start paying more for diminishing performance gains?\n",
    "\n",
    "## Why Should Consumers Care About the Death of Moore's Law?\n",
    "\n",
    "With the decline of Moore's Law, we can expect fewer improvements in transistor density in upcoming generations. This poses a concern for consumers, as we may start paying more for diminishing returns on performance. As traditional computing approaches its physical limits, incremental improvements will become smaller, potentially benefiting corporations more than consumers. This could lead to a scenario where consumers pay more for fewer benefits, which is undesirable.\n",
    "\n",
    "## The Economic Reality Today\n",
    "\n",
    "Inflation has steadily eroded purchasing power in the USA over the last 50 years. As inflation rises, the real cost of consumer goods, including technology, increases, affecting affordability. Here are links to inflation-related data:\n",
    "\n",
    "- [Purchasing power of the US dollar over time](https://elements.visualcapitalist.com/purchasing-power-of-the-u-s-dollar-over-time/)\n",
    "- [America's growing rent burden](https://www.axios.com/2023/05/22/americas-growing-rent-burden)\n",
    "\n",
    "## Purpose of This Project\n",
    "\n",
    "This project aims to answer the following key questions:\n",
    "\n",
    "1. What are the trends in CPU and GPU parts over the past 20 years?\n",
    "2. Is the price-to-performance ratio of these parts keeping up? Are consumers getting a fair deal compared to 10 to 20 years ago?\n",
    "3. Can we predict the performance of next-gen, unreleased CPU and GPU parts using supervised machine learning models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d226246f-fdfa-4162-8738-5b5c4973d714",
   "metadata": {},
   "source": [
    "## Data Collection & Description\n",
    "\n",
    "The data for both CPU/GPU was collected from:\n",
    "\n",
    "Note that various other sources were considered but was difficult to scrape/obtain or the data quality was not thorough enough. Hence they were skipped for the purposes of data source.\n",
    "- https://www.hwcompare.com/\n",
    "- https://www.userbenchmark.com/Software\n",
    "- https://www.tomshardware.com/reviews/gpu-hierarchy,4388.html\n",
    "- https://www.tomshardware.com/reviews/cpu-hierarchy,4312.html\n",
    "\n",
    "The script used to collect them is below (uncomment entire code to run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e05fe0-519f-46ce-97e2-49aaa8295cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2005_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2006_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2007_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2008_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2009_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2010_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "Pausing for 1 minute after 7 GPU iterations...\n",
      "2011_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2012_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2013_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2014_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2015_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2016_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2017_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "Pausing for 1 minute after 14 GPU iterations...\n",
      "2018_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2019_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2020_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2021_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2022_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2023_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2024_GPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "Pausing for 1 minute after 21 GPU iterations...\n",
      "2004_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2005_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2006_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2007_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2008_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2009_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2010_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "Pausing for 1 minute after 7 CPU iterations...\n",
      "2011_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2012_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2013_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2014_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2015_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2016_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2017_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "Pausing for 1 minute after 14 CPU iterations...\n",
      "2018_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2019_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2020_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2021_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2022_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2023_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "2024_CPU_database_TechPowerUp.html already exists. Skipping download.\n",
      "Pausing for 1 minute after 21 CPU iterations...\n",
      "Script finished!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Define the relative paths to save HTML files for GPU and CPU\n",
    "gpu_html_directory = os.path.join('..', 'data', 'gpu')\n",
    "cpu_html_directory = os.path.join('..', 'data', 'cpu')\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "for directory in [gpu_html_directory, cpu_html_directory]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# Base URLs for TechPowerUp GPU and CPU Specs by year\n",
    "gpu_base_url = 'https://www.techpowerup.com/gpu-specs/?released='\n",
    "cpu_base_url = 'https://www.techpowerup.com/cpu-specs/?released='\n",
    "\n",
    "# List of years from 2004 to 2024\n",
    "years = list(range(2004, 2024 + 1))\n",
    "\n",
    "def get_filename_from_year_and_type(year, spec_type):\n",
    "    # Generate the filename in the format <year>_<type>_database_TechPowerUp.html\n",
    "    return f'{year}_{spec_type}_database_TechPowerUp.html'\n",
    "\n",
    "def download_html_for_year(year, spec_type, base_url, directory):\n",
    "    full_url = f'{base_url}{year}&sort=name'\n",
    "    file_name = get_filename_from_year_and_type(year, spec_type)\n",
    "    file_path = os.path.join(directory, file_name)\n",
    "\n",
    "    # If file already exists, skip downloading\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"{file_name} already exists. Skipping download.\")\n",
    "        return True  # Indicate that the download was successful or skipped\n",
    "\n",
    "    try:\n",
    "        print(f\"Downloading {full_url}...\")\n",
    "        response = requests.get(full_url, timeout=10)  # Set a 10-second timeout for the request\n",
    "\n",
    "        # Check if request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Write the HTML content to a file\n",
    "            with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(response.text)\n",
    "            print(f\"Saved {file_name}\")\n",
    "            return True  # Indicate success\n",
    "        else:\n",
    "            print(f\"Error downloading {full_url}: {response.status_code}\")\n",
    "            return False  # Indicate failure\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"Timeout error occurred for {year}. Retrying...\")\n",
    "        return False  # Indicate failure due to timeout\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {full_url}: {e}\")\n",
    "        return False  # Indicate failure due to other exceptions\n",
    "\n",
    "# Function to handle downloading for both GPU and CPU\n",
    "def download_specs(spec_type, base_url, directory):\n",
    "    idx = 0\n",
    "    retries = 0\n",
    "    while idx < len(years):\n",
    "        year = years[idx]\n",
    "\n",
    "        success = download_html_for_year(year, spec_type, base_url, directory)\n",
    "        if success:\n",
    "            idx += 1  # Move to the next year only if the download is successful\n",
    "            retries = 0  # Reset retries after successful download\n",
    "        else:\n",
    "            retries += 1\n",
    "            if retries >= 3:\n",
    "                print(f\"Skipping year {year} after 3 failed attempts.\")\n",
    "                idx += 1  # Move to the next year after 3 failed attempts\n",
    "                retries = 0  # Reset retries for the next year\n",
    "            else:\n",
    "                print(f\"Retrying download for {spec_type} year {year} due to error...\")\n",
    "                time.sleep(10)  # Wait 10 seconds before retrying\n",
    "\n",
    "        time.sleep(1)  # Add a delay between requests to avoid overwhelming the server\n",
    "\n",
    "        # Pause for 1 minute after every 7 iterations\n",
    "        if idx % 7 == 0 and idx != 0:\n",
    "            print(f\"Pausing for 1 minute after {idx} {spec_type} iterations...\")\n",
    "            time.sleep(60)  # Sleep for 1 minute\n",
    "\n",
    "# Start downloading GPU and CPU specs\n",
    "download_specs('GPU', gpu_base_url, gpu_html_directory)\n",
    "download_specs('CPU', cpu_base_url, cpu_html_directory)\n",
    "print(\"Script finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b53d080-d1d1-4ba0-909e-3026059e0938",
   "metadata": {},
   "source": [
    "After running that, I went and manually grabbed the sublinks for all the GPU and CPU and stored them into a Python list to use for further webscraping for individual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe3e23-52b0-4226-9ae4-5efa561d9617",
   "metadata": {},
   "source": [
    "Please note that the website rate limits how much data you can scrape in a day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b87919-7a6f-4ac0-badc-b6be16240b26",
   "metadata": {},
   "source": [
    "## Data Collection & Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce7aa71-302a-4c57-96ac-0fc53dd7ab0b",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7faa96-69c3-4e3d-adb2-d94bf5e40806",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f920f69d-75e2-46f6-ae5f-cb89f8d8af76",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dce185-3bac-4732-aa7f-b24a85afaa5e",
   "metadata": {},
   "source": [
    "## Prediction & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092f31b3-58c8-40bb-8c88-cff66a3aafd0",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d2e3dc-0b04-4522-a441-8f64717704d1",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbbe16b-79f6-4679-9d11-18f17a5fded8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c7087-56ee-42c0-91e2-557e85ca70a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ec336-e3fe-4aa6-b914-e07f37866bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5732fe48-13e1-49e2-ab2c-f2683a86e3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998c1a2f-e9ba-4ba2-8a26-48d25d0b7a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
